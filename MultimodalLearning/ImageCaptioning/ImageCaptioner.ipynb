{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "26c3d2fe-1144-4d59-d653-5f32988cc611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BJ91dslNWeE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import pickle\n",
        "import string\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Model\n",
        "from numpy import array\n",
        "from pickle import load\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Dense,LSTM, Embedding, Dropout, add\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elEAY5wuJKAY"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/DataSets/Flicker/PreprocessedImages/VGG16/features.pickle'):\n",
        "\n",
        "  def extract_features(directory):\n",
        "    model = VGG16()\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "    print(model.summary())\n",
        "    features = dict()\n",
        "    for name in tqdm(listdir(directory)):\n",
        "      filename = directory + '/' + name\n",
        "      image = load_img(filename, target_size=(224, 224))\n",
        "      image = img_to_array(image)\n",
        "      image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "      image = preprocess_input(image)\n",
        "      feature = model.predict(image, verbose=0)\n",
        "      image_id = name.split('.')[0]\n",
        "      features[image_id] = feature\n",
        "    return features\n",
        "\n",
        "  directory = '/content/drive/MyDrive/DataSets/Flicker/Flickr8k_Dataset/Flicker8k_Dataset'\n",
        "  features = extract_features(directory)\n",
        "  print('Extracted Features: %d' % len(features))\n",
        "  pickle.dump(features, open('/content/drive/MyDrive/DataSets/Flicker/PreprocessedImages/VGG16/features.pickle', 'wb'))\n",
        "\n",
        "else:\n",
        "  features = None\n",
        "  with open('/content/drive/MyDrive/DataSets/Flicker/PreprocessedImages/VGG16/features.pickle', 'rb') as f:\n",
        "    features = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjDiSFNFJJtU"
      },
      "outputs": [],
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        " \n",
        "filename = '/content/drive/MyDrive/DataSets/Flicker/Flickr8k_text/Flickr8k.token.txt'\n",
        "doc = load_doc(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ipcPukaJJqc",
        "outputId": "62778c0f-14e1-4f30-fecd-70a48dae45ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: 8092 \n"
          ]
        }
      ],
      "source": [
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        " \n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMJdhWe_JJnW"
      },
      "outputs": [],
      "source": [
        "def clean_descriptions(descriptions):\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor i in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[i]\n",
        "\t\t\tdesc = desc.split()\n",
        "\t\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
        "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
        " \n",
        "clean_descriptions(descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFRvDXzwJJkK",
        "outputId": "74132f63-2e9d-405e-f1c4-548e6902f264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 8763\n"
          ]
        }
      ],
      "source": [
        "def to_vocabulary(descriptions):\n",
        "\tall_desc = set()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        " \n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZWATclZJJhm"
      },
      "outputs": [],
      "source": [
        "def save_descriptions(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        " \n",
        "save_descriptions(descriptions, '/content/drive/MyDrive/DataSets/Flicker/edited_descriptions.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlNp3_VZJJek",
        "outputId": "85ee6e2a-94a7-4800-cd23-2f941cccbdb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['child in pink dress is climbing up set of stairs in an entry way',\n",
              " 'girl going into wooden building',\n",
              " 'little girl climbing into wooden playhouse',\n",
              " 'little girl climbing the stairs to her playhouse',\n",
              " 'little girl in pink dress going into wooden cabin']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "descriptions['1000268201_693b08cb0e']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6EgQtNYJJZC"
      },
      "outputs": [],
      "source": [
        "def load_clean_descriptions(filename, dataset):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHk566gFJJWT"
      },
      "outputs": [],
      "source": [
        "def load_photo_features(filename, dataset):\n",
        "\tall_features = pickle.load(open(filename, 'rb'))\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BCzRynrJJTc",
        "outputId": "b894b0a7-5b82-4205-bdae-cdde8a025ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/DataSets/Flicker/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "train_descriptions = load_clean_descriptions('/content/drive/MyDrive/DataSets/Flicker/edited_descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "train_features = load_photo_features('/content/drive/MyDrive/DataSets/Flicker/PreprocessedImages/VGG16/features.pickle', train)\n",
        "print('Photos: train=%d' % len(train_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BURgUGnPJJPk",
        "outputId": "1aa83b80-4d3f-46f6-c4d3-909102ff9417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 7579\n"
          ]
        }
      ],
      "source": [
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        " \n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        " \n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrM7ma2AJJMt"
      },
      "outputs": [],
      "source": [
        "def create_sequences(tokenizer, max_length, desc_list, photo, vocab_size):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\tfor desc in desc_list:\n",
        "\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t\tfor i in range(1, len(seq)):\n",
        "\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t\tX1.append(photo)  \n",
        "\t\t\tX2.append(in_seq)\n",
        "\t\t\ty.append(out_seq)\n",
        "\treturn array(X1), array(X2), array(y)\n",
        "\n",
        "def data_generator(descriptions, photos, tokenizer, max_length, vocab_size):\n",
        "\twhile 1:\n",
        "\t\tfor key, desc_list in descriptions.items():\n",
        "\t\t\tphoto = photos[key][0]\n",
        "\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo, vocab_size)\n",
        "\t\t\tyield [in_img, in_seq], out_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOhR2nqkzOsN"
      },
      "outputs": [],
      "source": [
        "def get_max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)\n",
        "max_length = get_max_length(descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVbMxkhkpEzQ"
      },
      "outputs": [],
      "source": [
        "generator = data_generator(train_descriptions, train_features, tokenizer, max_length, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de0DEqBhxVAl",
        "outputId": "3a7f8fc9-5756-4f27-b271-c8de17d03da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47, 4096)\n",
            "(47, 32)\n",
            "(47, 7579)\n"
          ]
        }
      ],
      "source": [
        "inputs, outputs = next(generator)\n",
        "print(inputs[0].shape)\n",
        "print(inputs[1].shape)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_WJUCLrmgSt",
        "outputId": "8589321f-f9b3-4a40-be9c-d7bda0f54939"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_cNQVUzxXQp"
      },
      "outputs": [],
      "source": [
        "def define_model(vocab_size, max_length):\n",
        "\tinputs1 = Input(shape=(4096,))\n",
        "\tfe1 = Dropout(0.5)(inputs1)\n",
        "\tfe2 = Dense(256, activation='relu')(fe1)\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "\tse2 = Dropout(0.5)(se1)\n",
        "\tse3 = LSTM(256)(se2)\n",
        "\tdecoder1 = add([fe2, se3])\n",
        "\tdecoder2 = Dense(256, activation='relu')(decoder1)\n",
        "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer= keras.optimizers.Adam(learning_rate=0.003))\n",
        "\tprint(model.summary())\n",
        "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2Rkvnp_0SbZ",
        "outputId": "b28ce4f5-35c6-4528-a09b-0034f0e027f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n",
            "Vocabulary Size: 7579\n",
            "Description Length: 34\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/DataSets/Flicker/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "train_descriptions = load_clean_descriptions('/content/drive/MyDrive/DataSets/Flicker/edited_descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "train_features = load_photo_features('/content/drive/MyDrive/DataSets/Flicker/PreprocessedImages/VGG16/features.pickle', train)\n",
        "print('Photos: train=%d' % len(train_features))\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "max_length = get_max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)\n",
        "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions, train_features, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-0u23juqMRJ",
        "outputId": "94deb786-5bac-4ff9-a237-eb28fa018760"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X1train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoQOg4LY1kAq",
        "outputId": "48af4c5a-fab4-4104-9314-6c6d45d4218a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 1000\n",
            "Descriptions: test=1000\n",
            "Photos: test=1000\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/DataSets/Flicker/Flickr8k_text/Flickr_8k.devImages.txt'\n",
        "dev = load_set(filename)\n",
        "print('Dataset: %d' % len(dev))\n",
        "dev_descriptions = load_clean_descriptions('/content/drive/MyDrive/DataSets/Flicker/edited_descriptions.txt', dev)\n",
        "print('Descriptions: test=%d' % len(dev_descriptions))\n",
        "dev_features = load_photo_features('/content/drive/MyDrive/DataSets/Flicker/PreprocessedImages/VGG16/features.pickle', dev)\n",
        "print('Photos: test=%d' % len(dev_features))\n",
        "X1dev, X2dev, ydev = create_sequences(tokenizer, max_length, dev_descriptions, dev_features, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2maJWUoy_gqL",
        "outputId": "4920efa5-8885-4243-d78b-9e2168a30497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 34)]         0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 4096)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 34, 256)      1940224     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 4096)         0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 34, 256)      0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          1048832     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 256)          525312      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 256)          0           ['dense[0][0]',                  \n",
            "                                                                  'lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 7579)         1947803     ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,527,963\n",
            "Trainable params: 5,527,963\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = define_model(vocab_size, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEaTD37i_QUC",
        "outputId": "82457b9f-5195-4b0b-aee4-4c830f9c519b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6000/6000 [==============================] - 857s 142ms/step - loss: 4.7163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000/6000 [==============================] - 848s 141ms/step - loss: 4.1623\n",
            "6000/6000 [==============================] - 850s 142ms/step - loss: 4.0016\n",
            "6000/6000 [==============================] - 843s 141ms/step - loss: 3.8771\n",
            "6000/6000 [==============================] - 838s 140ms/step - loss: 3.8222\n",
            "6000/6000 [==============================] - 845s 141ms/step - loss: 3.7844\n",
            "6000/6000 [==============================] - 847s 141ms/step - loss: 3.7578\n",
            "6000/6000 [==============================] - 851s 142ms/step - loss: 3.7503\n",
            "6000/6000 [==============================] - 845s 141ms/step - loss: 3.7987\n",
            "6000/6000 [==============================] - 845s 141ms/step - loss: 3.7441\n",
            "6000/6000 [==============================] - 851s 142ms/step - loss: 3.7470\n",
            "5428/6000 [==========================>...] - ETA: 1:20 - loss: 3.7564"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "steps = len(train_descriptions)\n",
        "for i in range(epochs):\n",
        "\tgenerator = data_generator(train_descriptions, train_features, tokenizer, max_length, vocab_size)\n",
        "\tmodel.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "\tmodel.save('/content/drive/MyDrive/Models/Captioner/model' + str() + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFTO2emP2n7R"
      },
      "outputs": [],
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        " \n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\tin_text = 'startseq'\n",
        "\tfor i in range(max_length):\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\tyhat = np.argmax(yhat)\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\tin_text += ' ' + word\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s5CyWMm2tyg"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor key, desc_list in tqdm(descriptions.items()):\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\treferences = [d.split() for d in desc_list]\n",
        "\t\tactual.append(references)\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUG3UDjr3-xQ",
        "outputId": "a355e094-4d7d-44a5-8b89-8b2cc24a9bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 34)]         0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 4096)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 34, 256)      1940224     ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 4096)         0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 34, 256)      0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 256)          1048832     ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 256)          525312      ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 256)          0           ['dense_3[0][0]',                \n",
            "                                                                  'lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 256)          65792       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 7579)         1947803     ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,527,963\n",
            "Trainable params: 5,527,963\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "captioner = define_model(vocab_size, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKI9iRBZ4R8I",
        "outputId": "09d86b7c-467d-4c94-f03d-05a4741e0a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Vocabulary Size: 7579\n",
            "Description Length: 34\n",
            "Dataset: 6000\n",
            "Descriptions: test=6000\n",
            "Photos: test=6000\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/DataSets/Flicker/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "train_descriptions = load_clean_descriptions('/content/drive/MyDrive/DataSets/Flicker/edited_descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "max_length = get_max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)\n",
        " \n",
        "filename = '/content/drive/MyDrive/DataSets/Flicker/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "test = load_set(filename)\n",
        "print('Dataset: %d' % len(test))\n",
        "test_descriptions = load_clean_descriptions('/content/drive/MyDrive/DataSets/Flicker/edited_descriptions.txt', test)\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "test_features = load_photo_features('/content/drive/MyDrive/DataSets/Flicker/PreprocessedImages/VGG16/features.pickle', test)\n",
        "print('Photos: test=%d' % len(test_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC3jaeVD4ls3",
        "outputId": "68b3eb1f-c167-4dc2-83e0-db17ec5b1c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 34)]         0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 4096)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 34, 256)      1940224     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 4096)         0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 34, 256)      0           ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          1048832     ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 256)          525312      ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 256)          0           ['dense_6[0][0]',                \n",
            "                                                                  'lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 256)          65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 7579)         1947803     ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,527,963\n",
            "Trainable params: 5,527,963\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "captioner = define_model(vocab_size, max_length)\n",
        "captioner.load_weights('/content/drive/MyDrive/Models/Captioner/model_' + str(7) + '.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy_MGeq-39kA",
        "outputId": "176f296b-0b89-4668-cd18-1c011b557056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [43:57<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1: 0.393035\n",
            "BLEU-2: 0.148308\n",
            "BLEU-3: 0.090444\n",
            "BLEU-4: 0.037518\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(captioner, test_descriptions, test_features, tokenizer, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-63IoVk4641e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MLMIC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}