{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "from collections import defaultdict\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer() \n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Analyzer():\n",
    "    def __init__(self):\n",
    "        self.load_LDA_Weights()\n",
    "        self.load_SA_Model()\n",
    "        self.load_vectorizer()\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_negation(review):\n",
    "        review = re.sub(' +', ' ', review)\n",
    "        negation, delims, result, deleted_delim, words = False, \"?.,!:;\", [], False, review.split(\" \")\n",
    "        only_letter_pattern = re.compile('[^a-zA-Z]')\n",
    "        for word in words:\n",
    "            if (word not in stop_words) or (word == 'not' or word == 'no'):\n",
    "                if any(delim in word for delim in delims):\n",
    "                    deleted_delim = True\n",
    "                cleaned_word = only_letter_pattern.sub('', word).lower()\n",
    "                negated = \"not_\" + cleaned_word if negation else cleaned_word\n",
    "                if ((len(negated) >= 3 and 'not_' not in negated) or ('not_' in negated and len(negated) >= 7)) and len(negated) <= 25:\n",
    "                    result.append(negated)\n",
    "                if any(neg in word for neg in [\"not\", \"no\"]):\n",
    "                    negation = not negation\n",
    "                if deleted_delim:\n",
    "                    negation = False\n",
    "                    deleted_delim = False\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def edit(review):\n",
    "        only_letter_pattern, words, results = re.compile('[^a-zA-Z]'), review.split(\" \"), []\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                if len(word) >= 3 and len(word) <= 25:\n",
    "                    cleaned_word = only_letter_pattern.sub('', word).lower()\n",
    "                    results.append(cleaned_word)\n",
    "        return results\n",
    "        \n",
    "    \n",
    "    def normalize_text(self, list_of_reviews, Negate = False):\n",
    "        results = []\n",
    "        for i, review in enumerate(list_of_reviews):\n",
    "            token_roots = []\n",
    "            lower_cased_review = review.lower()\n",
    "            tokenized_review = lower_cased_review.split(\" \")          \n",
    "            for token in tokenized_review:\n",
    "                token_roots.append(lemmatizer.lemmatize(stemmer.stem(token)))\n",
    "            decontracted_review = contractions.fix(\" \".join(token_roots))\n",
    "            if Negate:\n",
    "                decontracted_review = self.apply_negation(decontracted_review)\n",
    "            else:\n",
    "                decontracted_review = self.edit(decontracted_review)\n",
    "            results.append(decontracted_review)\n",
    "        return results\n",
    "    \n",
    "    def load_LDA_Weights(self):\n",
    "        with open(\"NormalizedLDAW.pickle\",'rb') as f:\n",
    "            self.ldaw = pickle.load(f)\n",
    "        return None\n",
    "    \n",
    "    def load_SA_Model(self):\n",
    "        with open(\"LRNegModel.pickle\",'rb') as f:\n",
    "            self.SentimentAnalyzer = pickle.load(f)\n",
    "        return None\n",
    "    \n",
    "    def load_vectorizer(self):\n",
    "        with open(\"vectorizer.pickle\",'rb') as f:\n",
    "            self.vectorizer = pickle.load(f)\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def find_topic(self, review):\n",
    "        normalized_review = self.normalize_text(review)[0]\n",
    "        topic_scores, topic_names = [0,0,0,0,0],['iphone','battery&charge','screen','phone case','product&usability']\n",
    "        for token in normalized_review:\n",
    "            results = self.ldaw.loc[self.ldaw['word'] == token]\n",
    "            for i, score in enumerate(list(results['relevance'])):\n",
    "                topic_scores[i] += score\n",
    "        maxValueIndex = np.argmax(topic_scores)\n",
    "        return topic_names[maxValueIndex]\n",
    "    \n",
    "    def find_sentiment_Score(self, review):\n",
    "        normalized_review = self.normalize_text(review, Negate = True)[0]\n",
    "        transformed_vectorized_review = self.vectorizer.transform([\" \".join(normalized_review)])\n",
    "        sentiment_result = list(self.SentimentAnalyzer.predict(transformed_vectorized_review))[0]\n",
    "        sentiment_probabilities = self.SentimentAnalyzer.predict_proba(transformed_vectorized_review)\n",
    "        print(sentiment_probabilities)\n",
    "        case_prob, sentiment_score = None, None\n",
    "        if sentiment_result == 'negative':\n",
    "            case_prob = sentiment_probabilities[0][0]\n",
    "            sentiment_score = 5 - (4*case_prob)\n",
    "        else:\n",
    "            case_prob = sentiment_probabilities[0][1]\n",
    "            sentiment_score = 1 + (4*case_prob)\n",
    "        return sentiment_result, sentiment_score\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('reviews_Cell_Phones_and_Accessories_5.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_information = pd.DataFrame(df[['reviewText','overall']])\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194434</th>\n",
       "      <td>Works great just like my original one. I reall...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194435</th>\n",
       "      <td>Great product. Great packaging. High quality a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194436</th>\n",
       "      <td>This is a great cable, just as good as the mor...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194437</th>\n",
       "      <td>I really like it becasue it works well with my...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194438</th>\n",
       "      <td>product as described, I have wasted a lot of m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194439 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall\n",
       "0       They look good and stick good! I just don't li...        4\n",
       "1       These stickers work like the review says they ...        5\n",
       "2       These are awesome and make my phone look so st...        5\n",
       "3       Item arrived in great time and was in perfect ...        4\n",
       "4       awesome! stays on, and looks great. can be use...        5\n",
       "...                                                   ...      ...\n",
       "194434  Works great just like my original one. I reall...        5\n",
       "194435  Great product. Great packaging. High quality a...        5\n",
       "194436  This is a great cable, just as good as the mor...        5\n",
       "194437  I really like it becasue it works well with my...        5\n",
       "194438  product as described, I have wasted a lot of m...        5\n",
       "\n",
       "[194439 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = pd.DataFrame(needed_information['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Sentiment_Analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318.1023437976837\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "negated_data =a.normalize_text(needed_information['reviewText'], Negate = True)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302.7244338989258\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "edited_data = a.normalize_text(needed_information['reviewText'])\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(needed_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for tokens in edited_data:\n",
    "    sentences.append(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 87595)\t1\n",
      "  (0, 63508)\t2\n",
      "  (0, 147615)\t1\n",
      "  (0, 85936)\t2\n",
      "  (0, 132087)\t1\n",
      "  (0, 137462)\t1\n",
      "  (0, 13596)\t1\n",
      "  (0, 4496)\t1\n",
      "  (0, 19944)\t1\n",
      "  (0, 139975)\t1\n",
      "  (0, 82012)\t1\n",
      "  (0, 117198)\t1\n",
      "  (0, 78518)\t1\n",
      "  (0, 20751)\t1\n",
      "  (0, 120828)\t1\n",
      "  (1, 147615)\t1\n",
      "  (1, 85936)\t1\n",
      "  (1, 147620)\t1\n",
      "  (1, 175029)\t1\n",
      "  (1, 130346)\t1\n",
      "  (1, 133662)\t1\n",
      "  (1, 43462)\t1\n",
      "  (1, 64664)\t1\n",
      "  (1, 147296)\t1\n",
      "  (1, 112731)\t1\n",
      "  :\t:\n",
      "  (194437, 13591)\t1\n",
      "  (194438, 85936)\t1\n",
      "  (194438, 20751)\t1\n",
      "  (194438, 120828)\t1\n",
      "  (194438, 175029)\t2\n",
      "  (194438, 112731)\t2\n",
      "  (194438, 175917)\t1\n",
      "  (194438, 39619)\t1\n",
      "  (194438, 170683)\t1\n",
      "  (194438, 95229)\t1\n",
      "  (194438, 167308)\t1\n",
      "  (194438, 84339)\t1\n",
      "  (194438, 5784)\t1\n",
      "  (194438, 88140)\t1\n",
      "  (194438, 116035)\t1\n",
      "  (194438, 26729)\t1\n",
      "  (194438, 34033)\t2\n",
      "  (194438, 131486)\t1\n",
      "  (194438, 78949)\t1\n",
      "  (194438, 140029)\t1\n",
      "  (194438, 62535)\t1\n",
      "  (194438, 106810)\t1\n",
      "  (194438, 34145)\t1\n",
      "  (194438, 161758)\t1\n",
      "  (194438, 42702)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "negated_sentences = []\n",
    "for tokens in negated_data:\n",
    "    negated_sentences.append(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "negate_vectorized = negation_vectorizer.fit_transform(negated_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA and Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components = 5,random_state = 10,evaluate_every = -1,n_jobs = -1)\n",
    "lda_output = lda_model.fit_transform(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic1', 'Topic2', 'Topic3', 'Topic4', 'Topic5']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_names = [\"Topic\" + str(i) for i in range(1, lda_model.n_components + 1)]\n",
    "topic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output = np.round(lda_output, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.53, 0.25, 0.19, 0.01],\n",
       "       [0.01, 0.95, 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.95, 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.57, 0.01, 0.01, 0.41],\n",
       "       [0.01, 0.01, 0.52, 0.01, 0.44],\n",
       "       [0.01, 0.8 , 0.16, 0.01, 0.01],\n",
       "       [0.02, 0.93, 0.02, 0.02, 0.02],\n",
       "       [0.02, 0.72, 0.02, 0.21, 0.02],\n",
       "       [0.01, 0.01, 0.27, 0.71, 0.01],\n",
       "       [0.25, 0.17, 0.57, 0.01, 0.01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_output[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_topics = np.argmax(lda_output, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 4, 3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_keywords = pd.DataFrame(lda_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178256</th>\n",
       "      <th>178257</th>\n",
       "      <th>178258</th>\n",
       "      <th>178259</th>\n",
       "      <th>178260</th>\n",
       "      <th>178261</th>\n",
       "      <th>178262</th>\n",
       "      <th>178263</th>\n",
       "      <th>178264</th>\n",
       "      <th>178265</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203109</td>\n",
       "      <td>7.292670</td>\n",
       "      <td>0.201077</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.200049</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.713476</td>\n",
       "      <td>0.227651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202074</td>\n",
       "      <td>0.200667</td>\n",
       "      <td>0.201570</td>\n",
       "      <td>1.199766</td>\n",
       "      <td>1.199999</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>1.198788</td>\n",
       "      <td>0.202472</td>\n",
       "      <td>0.200002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.201840</td>\n",
       "      <td>1.762023</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200133</td>\n",
       "      <td>0.200098</td>\n",
       "      <td>0.200098</td>\n",
       "      <td>1.199835</td>\n",
       "      <td>0.213151</td>\n",
       "      <td>0.205464</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202374</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.196412</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.206578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.201615</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>0.200389</td>\n",
       "      <td>0.200278</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>0.200029</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.205028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197513</td>\n",
       "      <td>0.200135</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200186</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200362</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.070182</td>\n",
       "      <td>77.709664</td>\n",
       "      <td>1.815130</td>\n",
       "      <td>7.199478</td>\n",
       "      <td>1.199592</td>\n",
       "      <td>1.199592</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>1.186812</td>\n",
       "      <td>0.681058</td>\n",
       "      <td>1.128719</td>\n",
       "      <td>...</td>\n",
       "      <td>3.197952</td>\n",
       "      <td>2.198268</td>\n",
       "      <td>1.198427</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.199637</td>\n",
       "      <td>0.200935</td>\n",
       "      <td>0.201211</td>\n",
       "      <td>1.186475</td>\n",
       "      <td>1.193415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.323254</td>\n",
       "      <td>1.027049</td>\n",
       "      <td>1.583383</td>\n",
       "      <td>0.200066</td>\n",
       "      <td>0.200141</td>\n",
       "      <td>0.200141</td>\n",
       "      <td>0.200065</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200087</td>\n",
       "      <td>0.200929</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.202652</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.211047</td>\n",
       "      <td>0.200003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 178266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1         2         3         4         5         6       \\\n",
       "0   0.203109   7.292670  0.201077  0.200044  0.200107  0.200107  0.200049   \n",
       "1   0.201840   1.762023  0.200021  0.200133  0.200098  0.200098  1.199835   \n",
       "2   0.201615   0.208595  0.200389  0.200278  0.200063  0.200063  0.200029   \n",
       "3  54.070182  77.709664  1.815130  7.199478  1.199592  1.199592  0.200021   \n",
       "4   1.323254   1.027049  1.583383  0.200066  0.200141  0.200141  0.200065   \n",
       "\n",
       "     7         8         9       ...    178256    178257    178258    178259  \\\n",
       "0  0.200013  0.713476  0.227651  ...  0.202074  0.200667  0.201570  1.199766   \n",
       "1  0.213151  0.205464  0.238600  ...  0.202374  0.200001  0.200001  0.200000   \n",
       "2  0.200007  0.200001  0.205028  ...  1.197513  0.200135  0.200001  0.200186   \n",
       "3  1.186812  0.681058  1.128719  ...  3.197952  2.198268  1.198427  0.200047   \n",
       "4  0.200017  0.200002  0.200001  ...  0.200087  0.200929  0.200002  0.200000   \n",
       "\n",
       "     178260    178261    178262    178263    178264    178265  \n",
       "0  1.199999  0.200000  0.200001  1.198788  0.202472  0.200002  \n",
       "1  0.200000  0.200000  1.196412  0.200000  0.200003  0.206578  \n",
       "2  0.200000  0.200362  0.200000  0.200000  0.200002  0.200001  \n",
       "3  0.200000  4.199637  0.200935  0.201211  1.186475  1.193415  \n",
       "4  0.200001  0.200000  0.202652  0.200000  0.211047  0.200003  \n",
       "\n",
       "[5 rows x 178266 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_keywords = df_topic_keywords.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_keywords.columns = topic_names\n",
    "df_topic_keywords.index = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.203109</td>\n",
       "      <td>0.201840</td>\n",
       "      <td>0.201615</td>\n",
       "      <td>54.070182</td>\n",
       "      <td>1.323254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>7.292670</td>\n",
       "      <td>1.762023</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>77.709664</td>\n",
       "      <td>1.027049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>0.201077</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200389</td>\n",
       "      <td>1.815130</td>\n",
       "      <td>1.583383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200133</td>\n",
       "      <td>0.200278</td>\n",
       "      <td>7.199478</td>\n",
       "      <td>0.200066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaa</th>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.200098</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>1.199592</td>\n",
       "      <td>0.200141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Topic1    Topic2    Topic3     Topic4    Topic5\n",
       "aa      0.203109  0.201840  0.201615  54.070182  1.323254\n",
       "aaa     7.292670  1.762023  0.208595  77.709664  1.027049\n",
       "aaaa    0.201077  0.200021  0.200389   1.815130  1.583383\n",
       "aaaaa   0.200044  0.200133  0.200278   7.199478  0.200066\n",
       "aaaaaa  0.200107  0.200098  0.200063   1.199592  0.200141"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n"
     ]
    }
   ],
   "source": [
    "word_dominant_topic = []\n",
    "for i in range(df_topic_keywords.shape[0]):\n",
    "    if i % 20000 == 0:\n",
    "        print(i)\n",
    "    word_dominant_topic.append(np.argmax(df_topic_keywords.iloc[i]))\n",
    "word_dominant_topic = pd.DataFrame(word_dominant_topic, index = df_topic_keywords.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dominant_topic = word_dominant_topic.apply(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dominant topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaa</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dominant topic\n",
       "aa                   4\n",
       "aaa                  4\n",
       "aaaa                 4\n",
       "aaaaa                4\n",
       "aaaaaa               4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dominant_topic.columns = ['dominant topic']\n",
    "word_dominant_topic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_keywords = df_topic_keywords.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaaaaaaa</th>\n",
       "      <th>aaaaaal</th>\n",
       "      <th>aaaaabatteryst</th>\n",
       "      <th>aaaaalllllllllll</th>\n",
       "      <th>...</th>\n",
       "      <th>zx</th>\n",
       "      <th>zxr</th>\n",
       "      <th>zxrs</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zyxel</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzare</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzap</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.203109</td>\n",
       "      <td>7.292670</td>\n",
       "      <td>0.201077</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.200049</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.713476</td>\n",
       "      <td>0.227651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202074</td>\n",
       "      <td>0.200667</td>\n",
       "      <td>0.201570</td>\n",
       "      <td>1.199766</td>\n",
       "      <td>1.199999</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>1.198788</td>\n",
       "      <td>0.202472</td>\n",
       "      <td>0.200002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.201840</td>\n",
       "      <td>1.762023</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200133</td>\n",
       "      <td>0.200098</td>\n",
       "      <td>0.200098</td>\n",
       "      <td>1.199835</td>\n",
       "      <td>0.213151</td>\n",
       "      <td>0.205464</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202374</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.196412</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.206578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.201615</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>0.200389</td>\n",
       "      <td>0.200278</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>0.200029</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.205028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197513</td>\n",
       "      <td>0.200135</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200186</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200362</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>54.070182</td>\n",
       "      <td>77.709664</td>\n",
       "      <td>1.815130</td>\n",
       "      <td>7.199478</td>\n",
       "      <td>1.199592</td>\n",
       "      <td>1.199592</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>1.186812</td>\n",
       "      <td>0.681058</td>\n",
       "      <td>1.128719</td>\n",
       "      <td>...</td>\n",
       "      <td>3.197952</td>\n",
       "      <td>2.198268</td>\n",
       "      <td>1.198427</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.199637</td>\n",
       "      <td>0.200935</td>\n",
       "      <td>0.201211</td>\n",
       "      <td>1.186475</td>\n",
       "      <td>1.193415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>1.323254</td>\n",
       "      <td>1.027049</td>\n",
       "      <td>1.583383</td>\n",
       "      <td>0.200066</td>\n",
       "      <td>0.200141</td>\n",
       "      <td>0.200141</td>\n",
       "      <td>0.200065</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200087</td>\n",
       "      <td>0.200929</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.202652</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.211047</td>\n",
       "      <td>0.200003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 178266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               aa        aaa      aaaa     aaaaa    aaaaaa  aaaaaaaa  \\\n",
       "Topic1   0.203109   7.292670  0.201077  0.200044  0.200107  0.200107   \n",
       "Topic2   0.201840   1.762023  0.200021  0.200133  0.200098  0.200098   \n",
       "Topic3   0.201615   0.208595  0.200389  0.200278  0.200063  0.200063   \n",
       "Topic4  54.070182  77.709664  1.815130  7.199478  1.199592  1.199592   \n",
       "Topic5   1.323254   1.027049  1.583383  0.200066  0.200141  0.200141   \n",
       "\n",
       "        aaaaaaaaa   aaaaaal  aaaaabatteryst  aaaaalllllllllll  ...        zx  \\\n",
       "Topic1   0.200049  0.200013        0.713476          0.227651  ...  0.202074   \n",
       "Topic2   1.199835  0.213151        0.205464          0.238600  ...  0.202374   \n",
       "Topic3   0.200029  0.200007        0.200001          0.205028  ...  1.197513   \n",
       "Topic4   0.200021  1.186812        0.681058          1.128719  ...  3.197952   \n",
       "Topic5   0.200065  0.200017        0.200002          0.200001  ...  0.200087   \n",
       "\n",
       "             zxr      zxrs     zynga     zyxel        zz     zzare       zzz  \\\n",
       "Topic1  0.200667  0.201570  1.199766  1.199999  0.200000  0.200001  1.198788   \n",
       "Topic2  0.200001  0.200001  0.200000  0.200000  0.200000  1.196412  0.200000   \n",
       "Topic3  0.200135  0.200001  0.200186  0.200000  0.200362  0.200000  0.200000   \n",
       "Topic4  2.198268  1.198427  0.200047  0.200000  4.199637  0.200935  0.201211   \n",
       "Topic5  0.200929  0.200002  0.200000  0.200001  0.200000  0.202652  0.200000   \n",
       "\n",
       "           zzzap      zzzs  \n",
       "Topic1  0.202472  0.200002  \n",
       "Topic2  0.200003  0.206578  \n",
       "Topic3  0.200002  0.200001  \n",
       "Topic4  1.186475  1.193415  \n",
       "Topic5  0.211047  0.200003  \n",
       "\n",
       "[5 rows x 178266 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_names = df_topic_keywords.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic1     phone\n",
       "Topic2     phone\n",
       "Topic3      case\n",
       "Topic4     charg\n",
       "Topic5    screen\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_keywords = df_topic_keywords.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.203109</td>\n",
       "      <td>0.201840</td>\n",
       "      <td>0.201615</td>\n",
       "      <td>54.070182</td>\n",
       "      <td>1.323254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>7.292670</td>\n",
       "      <td>1.762023</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>77.709664</td>\n",
       "      <td>1.027049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>0.201077</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200389</td>\n",
       "      <td>1.815130</td>\n",
       "      <td>1.583383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.200133</td>\n",
       "      <td>0.200278</td>\n",
       "      <td>7.199478</td>\n",
       "      <td>0.200066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaa</th>\n",
       "      <td>0.200107</td>\n",
       "      <td>0.200098</td>\n",
       "      <td>0.200063</td>\n",
       "      <td>1.199592</td>\n",
       "      <td>0.200141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Topic1    Topic2    Topic3     Topic4    Topic5\n",
       "aa      0.203109  0.201840  0.201615  54.070182  1.323254\n",
       "aaa     7.292670  1.762023  0.208595  77.709664  1.027049\n",
       "aaaa    0.201077  0.200021  0.200389   1.815130  1.583383\n",
       "aaaaa   0.200044  0.200133  0.200278   7.199478  0.200066\n",
       "aaaaaa  0.200107  0.200098  0.200063   1.199592  0.200141"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20310893, 7.29266995, 0.20107699, ..., 0.20000025, 1.19878825,\n",
       "       0.20000236])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords['Topic1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'word': df_topic_keywords.index, 'Topic':'Topic1', 'relevance':df_topic_keywords['Topic1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.append(pd.DataFrame({'word': df_topic_keywords.index,'Topic':'Topic2', 'relevance':df_topic_keywords['Topic2']}), ignore_index = True)\n",
    "new_df = new_df.append(pd.DataFrame({'word': df_topic_keywords.index,'Topic':'Topic3', 'relevance':df_topic_keywords['Topic3']}), ignore_index = True)\n",
    "new_df = new_df.append(pd.DataFrame({'word': df_topic_keywords.index,'Topic':'Topic4', 'relevance':df_topic_keywords['Topic4']}), ignore_index = True)\n",
    "new_df = new_df.append(pd.DataFrame({'word': df_topic_keywords.index,'Topic':'Topic5', 'relevance':df_topic_keywords['Topic5']}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads the best weights that have been learned, others shouldnt run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"LDA_CV_unibigram_relevanceWeights.pickle\",'rb') as f:\n",
    "    new_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2000010672638451,\n",
       " 0.2054899632530272,\n",
       " 0.20000027712947194,\n",
       " 0.20000017643262982,\n",
       " 1.1945085136737106]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_df.loc[new_df['word']=='aa aaa']['relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "new_df.loc[new_df['Topic'] == 'Topic1']['relevance'] = (new_df.loc[new_df['Topic'] == 'Topic1']['relevance']/np.max(new_df.loc[new_df['Topic'] == 'Topic1']['relevance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Topic</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12673117</th>\n",
       "      <td>use</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>22977.327362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11901484</th>\n",
       "      <td>phone</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>22155.770680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11227470</th>\n",
       "      <td>great</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>19225.236456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12803278</th>\n",
       "      <td>work</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>15508.370299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12819028</th>\n",
       "      <td>would</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>14811.717304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12699542</th>\n",
       "      <td>veri</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>14043.624336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11793885</th>\n",
       "      <td>one</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>13527.707301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018930</th>\n",
       "      <td>product</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>12755.964985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519774</th>\n",
       "      <td>like</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>11422.412373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11424121</th>\n",
       "      <td>it</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>11276.878054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word   Topic     relevance\n",
       "12673117      use  Topic5  22977.327362\n",
       "11901484    phone  Topic5  22155.770680\n",
       "11227470    great  Topic5  19225.236456\n",
       "12803278     work  Topic5  15508.370299\n",
       "12819028    would  Topic5  14811.717304\n",
       "12699542     veri  Topic5  14043.624336\n",
       "11793885      one  Topic5  13527.707301\n",
       "12018930  product  Topic5  12755.964985\n",
       "11519774     like  Topic5  11422.412373\n",
       "11424121       it  Topic5  11276.878054"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[new_df['Topic'] == 'Topic5'].sort_values('relevance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "new_df.loc[new_df['Topic'] == 'Topic1']['relevance'] = (new_df.loc[new_df['Topic'] == 'Topic1']['relevance']/np.max(new_df.loc[new_df['Topic'] == 'Topic1']['relevance']))\n",
    "new_df.loc[new_df['Topic'] == 'Topic2']['relevance'] = (new_df.loc[new_df['Topic'] == 'Topic2']['relevance']/np.max(new_df.loc[new_df['Topic'] == 'Topic2']['relevance']))\n",
    "new_df.loc[new_df['Topic'] == 'Topic3']['relevance'] = (new_df.loc[new_df['Topic'] == 'Topic3']['relevance']/np.max(new_df.loc[new_df['Topic'] == 'Topic3']['relevance']))\n",
    "new_df.loc[new_df['Topic'] == 'Topic4']['relevance'] = (new_df.loc[new_df['Topic'] == 'Topic4']['relevance']/np.max(new_df.loc[new_df['Topic'] == 'Topic4']['relevance']))\n",
    "new_df.loc[new_df['Topic'] == 'Topic5']['relevance'] = (new_df.loc[new_df['Topic'] == 'Topic5']['relevance']/np.max(new_df.loc[new_df['Topic'] == 'Topic5']['relevance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Topic</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12673117</th>\n",
       "      <td>use</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>22977.327362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11901484</th>\n",
       "      <td>phone</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>22155.770680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11227470</th>\n",
       "      <td>great</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>19225.236456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12803278</th>\n",
       "      <td>work</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>15508.370299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12819028</th>\n",
       "      <td>would</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>14811.717304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12699542</th>\n",
       "      <td>veri</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>14043.624336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11793885</th>\n",
       "      <td>one</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>13527.707301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018930</th>\n",
       "      <td>product</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>12755.964985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519774</th>\n",
       "      <td>like</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>11422.412373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11424121</th>\n",
       "      <td>it</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>11276.878054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word   Topic     relevance\n",
       "12673117      use  Topic5  22977.327362\n",
       "11901484    phone  Topic5  22155.770680\n",
       "11227470    great  Topic5  19225.236456\n",
       "12803278     work  Topic5  15508.370299\n",
       "12819028    would  Topic5  14811.717304\n",
       "12699542     veri  Topic5  14043.624336\n",
       "11793885      one  Topic5  13527.707301\n",
       "12018930  product  Topic5  12755.964985\n",
       "11519774     like  Topic5  11422.412373\n",
       "11424121       it  Topic5  11276.878054"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[new_df['Topic'] == 'Topic5'].sort_values('relevance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to save the result weights, Run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LDA_CV_unibigram_relevanceWeights.pickle\", 'wb') as f:\n",
    "    pickle.dump(new_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sentiment Analysis Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sentiment_scores['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "tm = defaultdict(lambda: 0)\n",
    "for score in sentiment_scores['overall']:\n",
    "    tm[score] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  :  39993\n",
      "5  :  108664\n",
      "3  :  21439\n",
      "1  :  13279\n",
      "2  :  11064\n"
     ]
    }
   ],
   "source": [
    "for key in tm.keys():\n",
    "    print(key, \" : \", tm[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "for score in sentiment_scores['overall']:\n",
    "    if int(score) > 3:\n",
    "        sentiments.append('positive')\n",
    "    else:\n",
    "        sentiments.append('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(texts,sentiments,count, label):\n",
    "    label_reviews ,reviews = [], [[None,None] for i in range(len(texts))]\n",
    "    for i, text in enumerate(texts):\n",
    "        reviews[i][0] = text\n",
    "    for i, lable in enumerate(sentiments):\n",
    "        reviews[i][1] = lable\n",
    "        \n",
    "    random.shuffle(reviews)\n",
    "    for review in reviews:\n",
    "        if review[1] == label:\n",
    "            label_reviews.append(review)\n",
    "            if len(label_reviews) == count:\n",
    "                break\n",
    "    for review in reviews:\n",
    "        if review[1] != label:\n",
    "            label_reviews.append(review)\n",
    "    reviewText, reviewSentiment = [s[0] for s in label_reviews], [s[1] for s in label_reviews]\n",
    "    return reviewText, reviewSentiment\n",
    "            \n",
    "\n",
    "\n",
    "def calculate_sentiment_percentage(sentiments):\n",
    "    pos , neg = 0,0\n",
    "    for label in sentiments:\n",
    "        if label == 'positive':\n",
    "            pos += 1\n",
    "        elif label == 'negative':\n",
    "            neg += 1\n",
    "    return pos/len(sentiments),  neg/len(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7645431214931161, 0.2354568785068839)\n"
     ]
    }
   ],
   "source": [
    "print(calculate_sentiment_percentage(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5220187509135328, 0.47798124908646716)\n"
     ]
    }
   ],
   "source": [
    "reviews_subset, labels_subset = get_reviews(edited_data,sentiments,50000, 'positive')\n",
    "print(calculate_sentiment_percentage(labels_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5220187509135328, 0.47798124908646716)\n"
     ]
    }
   ],
   "source": [
    "neg_reviews_subset, neg_labels_subset = get_reviews(negated_data,sentiments,50000, 'positive')\n",
    "print(calculate_sentiment_percentage(labels_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for tokens in reviews_subset:\n",
    "    sentences.append(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_edited_vectorizer = TfidfVectorizer()\n",
    "ed_vectorized = model_edited_vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sentences = []\n",
    "for tokens in neg_reviews_subset:\n",
    "    neg_sentences.append(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_negated_vectorizer = TfidfVectorizer()\n",
    "negated_vectorized = model_negated_vectorizer.fit_transform(neg_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ed_vectorized, labels_subset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7772093751631257"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.69      0.75      9079\n",
      "    positive       0.75      0.86      0.80     10078\n",
      "\n",
      "    accuracy                           0.78     19157\n",
      "   macro avg       0.78      0.77      0.77     19157\n",
      "weighted avg       0.78      0.78      0.78     19157\n",
      "\n",
      "[[6257 2822]\n",
      " [1446 8632]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_train, Xn_test, yn_train, yn_test = train_test_split(negated_vectorized, neg_labels_subset, test_size=0.23, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nClf.fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn_pred = nClf.predict(Xn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAcc = metrics.accuracy_score(yn_test,yn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802265490421256"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78      9146\n",
      "    positive       0.78      0.87      0.82     10011\n",
      "\n",
      "    accuracy                           0.80     19157\n",
      "   macro avg       0.81      0.80      0.80     19157\n",
      "weighted avg       0.81      0.80      0.80     19157\n",
      "\n",
      "[[6669 2477]\n",
      " [1311 8700]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yn_test,yn_pred))\n",
    "print(confusion_matrix(yn_test,yn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lry_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y_test,lry_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745993631570706"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.76      0.76      9079\n",
      "    positive       0.79      0.78      0.79     10078\n",
      "\n",
      "    accuracy                           0.77     19157\n",
      "   macro avg       0.77      0.77      0.77     19157\n",
      "weighted avg       0.77      0.77      0.77     19157\n",
      "\n",
      "[[6942 2137]\n",
      " [2181 7897]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,lry_pred))\n",
    "print(confusion_matrix(y_test,lry_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglogreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglogreg.fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lry_pred = neglogreg.predict(Xn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(yn_test,lry_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301861098502042"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.82     10562\n",
      "    positive       0.83      0.84      0.84     11468\n",
      "\n",
      "    accuracy                           0.83     22030\n",
      "   macro avg       0.83      0.83      0.83     22030\n",
      "weighted avg       0.83      0.83      0.83     22030\n",
      "\n",
      "[[8621 1941]\n",
      " [1800 9668]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yn_test,lry_pred))\n",
    "print(confusion_matrix(yn_test,lry_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "erfclf = RandomForestClassifier(n_estimators=101,max_depth=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=101, random_state=0)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erfclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "erf_ypred = erfclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y_test,erf_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5654852012319257"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.09      0.16      9079\n",
      "    positive       0.55      0.99      0.71     10078\n",
      "\n",
      "    accuracy                           0.57     19157\n",
      "   macro avg       0.74      0.54      0.43     19157\n",
      "weighted avg       0.73      0.57      0.45     19157\n",
      "\n",
      "[[  808  8271]\n",
      " [   53 10025]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,erf_ypred))\n",
    "print(confusion_matrix(y_test,erf_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## negated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrfclf = RandomForestClassifier(n_estimators=101,max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_estimators=101, random_state=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrfclf.fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrf_ypred = nrfclf.predict(Xn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(yn_test,nrf_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5222877893781207"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "esvmclf = svm.SVC(kernel = 'linear', C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, kernel='linear')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esvmclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ypred = esvmclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y_test,svm_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068591115519131"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.80      0.80      9079\n",
      "    positive       0.82      0.81      0.82     10078\n",
      "\n",
      "    accuracy                           0.81     19157\n",
      "   macro avg       0.81      0.81      0.81     19157\n",
      "weighted avg       0.81      0.81      0.81     19157\n",
      "\n",
      "[[7261 1818]\n",
      " [1882 8196]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm_ypred))\n",
    "print(confusion_matrix(y_test,svm_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsvmclf = svm.SVC(kernel = 'linear', C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, kernel='linear')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsvmclf.fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsvm_ypred = nsvmclf.predict(Xn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(yn_test,nsvm_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826781661370858"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.82     10562\n",
      "    positive       0.83      0.84      0.83     11468\n",
      "\n",
      "    accuracy                           0.83     22030\n",
      "   macro avg       0.83      0.83      0.83     22030\n",
      "weighted avg       0.83      0.83      0.83     22030\n",
      "\n",
      "[[8582 1980]\n",
      " [1836 9632]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yn_test,nsvm_ypred))\n",
    "print(confusion_matrix(yn_test,nsvm_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(normalized_review):\n",
    "    topic_scores, topic_names = [0,0,0,0,0],['','','','','']\n",
    "    for token in normalized_review:\n",
    "        results = self.ldaw.loc[self.ldaw['word'] == token]\n",
    "        for i, score in enumretate(list(results['relevance'])):\n",
    "            topic_scores[i] += score\n",
    "    maxValueIndex = np.argmax(topic_scores)\n",
    "    return topic_names[maxValueIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Sentiment_Analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "u = a.normalize_text([\"This is the first battery case I have had for my Galaxy S4. The S4 fits very well, is slim and doesn't add much weight to the Galaxy S4. It doubles the battery life. You can charge either the battery, the phone or both. There is a handy on-off switch with leds to indicate the level of charge.The battery case came on time and was packaged well. Well worth the price.\"], Negate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone case\n"
     ]
    }
   ],
   "source": [
    "print(a.find_topic(u[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95782 95782\n",
      "['tri', 'hammer', 'cell', 'phone', 'layer', 'commando', 'provid', 'protect', 'phone', 'without', 'case', 'it', 'see', 'ani', 'ding', 'anything', 'even', 'drop', 'time', 'without', 'ani', 'scratches']\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_subset), len(labels_subset))\n",
    "print(reviews_subset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = defaultdict(lambda: defaultdict(lambda : 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery&charge : positive : 176\n",
      "product&usability : positive : 2324\n",
      "iphone : positive : 576\n",
      "phone case : positive : 273\n",
      "screen : positive : 156\n"
     ]
    }
   ],
   "source": [
    "for key in count.keys():\n",
    "    for k in count[key].keys():\n",
    "        print(key, \":\", k, \":\", count[key][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count['battery&charge']['negative'] = 80\n",
    "count['product&usability']['negative'] = 1758\n",
    "count['iphone']['negative'] =  179\n",
    "count['phone case']['negative'] =  321\n",
    "count['screen']['negative'] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [(x[0],x[1]) for x in zip(reviews_subset,labels_subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for i , x in enumerate(tmp):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "for i,pair in enumerate(tmp):\n",
    "    if i == 1500:\n",
    "        break\n",
    "    if i% 100 == 0:\n",
    "        print(i)\n",
    "    revtopic = a.find_topic(pair[0])\n",
    "    count[revtopic][pair[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product&usability : negative : 474\n",
      "product&usability : positive : 521\n",
      "phone case : negative : 83\n",
      "phone case : positive : 52\n",
      "iphone : positive : 123\n",
      "iphone : negative : 112\n",
      "screen : negative : 30\n",
      "screen : positive : 27\n",
      "battery&charge : positive : 36\n",
      "battery&charge : negative : 42\n"
     ]
    }
   ],
   "source": [
    "for key in count.keys():\n",
    "    for k in count[key].keys():\n",
    "        print(key, \":\", k, \":\", count[key][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "revvec = model_negated_vectorizer.transform([\" \".join(u[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 129733)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95782, 110025)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_negated_vectorizer = TfidfVectorizer()\n",
    "negated_vectorized = model_negated_vectorizer.fit_transform(neg_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "u = a.normalize_text([\"This is the first battery case I have had for my Galaxy S4. The S4 fits very well, is slim and doesn't add much weight to the Galaxy S4. It doubles the battery life. You can charge either the battery, the phone or both. There is a handy on-off switch with leds to indicate the level of charge.The battery case came on time and was packaged well. Well worth the price.\"], Negate = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "revvec = model_negated_vectorizer.transform([\" \".join(u)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U8')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglogreg.predict(revvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01993882, 0.98006118]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglogreg.predict_proba(revvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x129733 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negated_vectorized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pickle\", 'wb') as f:\n",
    "    pickle.dump(model_negated_vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LRNegModel.pickle\", 'wb') as f:\n",
    "    pickle.dump(neglogreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Sentiment_Analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0.72743339 0.27256661]]\n",
      "('negative', 2.09026645506371)\n"
     ]
    }
   ],
   "source": [
    "print(a.find_sentiment_Score([\"This case for some reason is peeling, there isn't much left of the orginal skin, i  loved the case with pink being my favorite color but i wouldn't recommend this specific one for anyone.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0.01993882 0.98006118]]\n",
      "('positive', 4.92024472494391)\n"
     ]
    }
   ],
   "source": [
    "print(a.find_sentiment_Score([\"This is the first battery case I have had for my Galaxy S4. The S4 fits very well, is slim and doesn't add much weight to the Galaxy S4. It doubles the battery life. You can charge either the battery, the phone or both. There is a handy on-off switch with leds to indicate the level of charge.The battery case came on time and was packaged well. Well worth the price.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Topic</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa aaa</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa batteri</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa batteries</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa batterypowered</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846945</th>\n",
       "      <td>zzz doe</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846946</th>\n",
       "      <td>zzzap</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846947</th>\n",
       "      <td>zzzap refundrevis</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846948</th>\n",
       "      <td>zzzs</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846949</th>\n",
       "      <td>zzzs rate</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12846950 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       word   Topic  relevance\n",
       "0                        aa  Topic1   0.000143\n",
       "1                    aa aaa  Topic1   0.000143\n",
       "2                aa batteri  Topic1   0.000143\n",
       "3              aa batteries  Topic1   0.000143\n",
       "4         aa batterypowered  Topic1   0.000143\n",
       "...                     ...     ...        ...\n",
       "12846945            zzz doe  Topic5   0.000009\n",
       "12846946              zzzap  Topic5   0.000009\n",
       "12846947  zzzap refundrevis  Topic5   0.000009\n",
       "12846948               zzzs  Topic5   0.000009\n",
       "12846949          zzzs rate  Topic5   0.000009\n",
       "\n",
       "[12846950 rows x 3 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ldaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.5415686063592394, 0.8967462101018147, 1.0581275315356513, 2.8650851822266263, 2.7302151023993138]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'phone case'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.find_topic([\"This case for some reason is peeling, there isn't much left of the orginal skin, i  loved the case with pink being my favorite color but i wouldn't recommend this specific one for anyone.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing LDA Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(a.ldaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_list = []\n",
    "for i in range(1,6):\n",
    "    tmp_list.append(tmp.loc[tmp['Topic'] == 'Topic'+str(i)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehrad/Programmings/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    v = np.max(list(tmp_list[i]['relevance']))\n",
    "    tmp_list[i]['relevance'] = (tmp_list[i]['relevance']/v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.60159676e-05, 5.19863992e-05, 2.11207061e-05, ...,\n",
       "       8.70431165e-06, 8.70426339e-06, 8.70426339e-06])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tmp_list[4]['relevance'])/z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.max(list(tmp_list[4]['relevance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Topic</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2947815</th>\n",
       "      <td>charg</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964947</th>\n",
       "      <td>use</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.562245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956516</th>\n",
       "      <td>charger</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.546971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756010</th>\n",
       "      <td>batteri</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.515879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095108</th>\n",
       "      <td>work</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.379402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193314</th>\n",
       "      <td>phone</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.378801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085715</th>\n",
       "      <td>one</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.346064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962310</th>\n",
       "      <td>usb</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.339843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160685</th>\n",
       "      <td>devic</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.300153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272374</th>\n",
       "      <td>power</td>\n",
       "      <td>Topic2</td>\n",
       "      <td>0.283719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word   Topic  relevance\n",
       "2947815    charg  Topic2   1.000000\n",
       "4964947      use  Topic2   0.562245\n",
       "2956516  charger  Topic2   0.546971\n",
       "2756010  batteri  Topic2   0.515879\n",
       "5095108     work  Topic2   0.379402\n",
       "4193314    phone  Topic2   0.378801\n",
       "4085715      one  Topic2   0.346064\n",
       "4962310      usb  Topic2   0.339843\n",
       "3160685    devic  Topic2   0.300153\n",
       "4272374    power  Topic2   0.283719"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list[1].sort_values('relevance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'word': tmp_list[0]['word'], 'Topic':'Topic1', 'relevance':tmp_list[0]['relevance']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.append(pd.DataFrame({'word': tmp_list[1]['word'],'Topic':'Topic2', 'relevance':tmp_list[1]['relevance']}), ignore_index = True)\n",
    "new_df = new_df.append(pd.DataFrame({'word': tmp_list[2]['word'],'Topic':'Topic3', 'relevance':tmp_list[2]['relevance']}), ignore_index = True)\n",
    "new_df = new_df.append(pd.DataFrame({'word': tmp_list[3]['word'],'Topic':'Topic4', 'relevance':tmp_list[3]['relevance']}), ignore_index = True)\n",
    "new_df = new_df.append(pd.DataFrame({'word': tmp_list[4]['word'],'Topic':'Topic5', 'relevance':tmp_list[4]['relevance']}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Topic</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa aaa</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa batteri</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa batteries</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa batterypowered</td>\n",
       "      <td>Topic1</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846945</th>\n",
       "      <td>zzz doe</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846946</th>\n",
       "      <td>zzzap</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846947</th>\n",
       "      <td>zzzap refundrevis</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846948</th>\n",
       "      <td>zzzs</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846949</th>\n",
       "      <td>zzzs rate</td>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12846950 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       word   Topic  relevance\n",
       "0                        aa  Topic1   0.000143\n",
       "1                    aa aaa  Topic1   0.000143\n",
       "2                aa batteri  Topic1   0.000143\n",
       "3              aa batteries  Topic1   0.000143\n",
       "4         aa batterypowered  Topic1   0.000143\n",
       "...                     ...     ...        ...\n",
       "12846945            zzz doe  Topic5   0.000009\n",
       "12846946              zzzap  Topic5   0.000009\n",
       "12846947  zzzap refundrevis  Topic5   0.000009\n",
       "12846948               zzzs  Topic5   0.000009\n",
       "12846949          zzzs rate  Topic5   0.000009\n",
       "\n",
       "[12846950 rows x 3 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NormalizedLDAW.pickle','wb') as f:\n",
    "    pickle.dump(new_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
